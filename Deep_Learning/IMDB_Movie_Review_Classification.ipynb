{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to one-hot encode the words in each sequence in vector\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    vectorized_sequences = np.zeros((len(sequences), dimension), dtype='float32')\n",
    "    for i, sequence in enumerate(sequences, start=0):\n",
    "        vectorized_sequences[i, sequence] = 1.\n",
    "    return vectorized_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pradip/anaconda3/lib/python3.7/site-packages/keras/datasets/imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/pradip/anaconda3/lib/python3.7/site-packages/keras/datasets/imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Loads and prepares data\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum word index in training data:  9999\n"
     ]
    }
   ],
   "source": [
    "# Checks the maximum word index in training data\n",
    "print(\"Maximum word index in training data: \", max([np.max(seq) for seq in train_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gets the review comment in English just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_dict = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverses the order of key and value pairs to search word against its index found in training data \n",
    "index_word_dict = dict([(key, word) for (word, key) in word_index_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34701: 'fawn',\n",
       " 52006: 'tsukino',\n",
       " 52007: 'nunnery',\n",
       " 16816: 'sonja',\n",
       " 63951: 'vani',\n",
       " 1408: 'woods',\n",
       " 16115: 'spiders',\n",
       " 2345: 'hanging',\n",
       " 2289: 'woody',\n",
       " 52008: 'trawling',\n",
       " 52009: \"hold's\",\n",
       " 11307: 'comically',\n",
       " 40830: 'localized',\n",
       " 30568: 'disobeying',\n",
       " 52010: \"'royale\",\n",
       " 40831: \"harpo's\",\n",
       " 52011: 'canet',\n",
       " 19313: 'aileen',\n",
       " 52012: 'acurately',\n",
       " 52013: \"diplomat's\",\n",
       " 25242: 'rickman',\n",
       " 6746: 'arranged',\n",
       " 52014: 'rumbustious',\n",
       " 52015: 'familiarness',\n",
       " 52016: \"spider'\",\n",
       " 68804: 'hahahah',\n",
       " 52017: \"wood'\",\n",
       " 40833: 'transvestism',\n",
       " 34702: \"hangin'\",\n",
       " 2338: 'bringing',\n",
       " 40834: 'seamier',\n",
       " 34703: 'wooded',\n",
       " 52018: 'bravora',\n",
       " 16817: 'grueling',\n",
       " 1636: 'wooden',\n",
       " 16818: 'wednesday',\n",
       " 52019: \"'prix\",\n",
       " 34704: 'altagracia',\n",
       " 52020: 'circuitry',\n",
       " 11585: 'crotch',\n",
       " 57766: 'busybody',\n",
       " 52021: \"tart'n'tangy\",\n",
       " 14129: 'burgade',\n",
       " 52023: 'thrace',\n",
       " 11038: \"tom's\",\n",
       " 52025: 'snuggles',\n",
       " 29114: 'francesco',\n",
       " 52027: 'complainers',\n",
       " 52125: 'templarios',\n",
       " 40835: '272',\n",
       " 52028: '273',\n",
       " 52130: 'zaniacs',\n",
       " 34706: '275',\n",
       " 27631: 'consenting',\n",
       " 40836: 'snuggled',\n",
       " 15492: 'inanimate',\n",
       " 52030: 'uality',\n",
       " 11926: 'bronte',\n",
       " 4010: 'errors',\n",
       " 3230: 'dialogs',\n",
       " 52031: \"yomada's\",\n",
       " 34707: \"madman's\",\n",
       " 30585: 'dialoge',\n",
       " 52033: 'usenet',\n",
       " 40837: 'videodrome',\n",
       " 26338: \"kid'\",\n",
       " 52034: 'pawed',\n",
       " 30569: \"'girlfriend'\",\n",
       " 52035: \"'pleasure\",\n",
       " 52036: \"'reloaded'\",\n",
       " 40839: \"kazakos'\",\n",
       " 52037: 'rocque',\n",
       " 52038: 'mailings',\n",
       " 11927: 'brainwashed',\n",
       " 16819: 'mcanally',\n",
       " 52039: \"tom''\",\n",
       " 25243: 'kurupt',\n",
       " 21905: 'affiliated',\n",
       " 52040: 'babaganoosh',\n",
       " 40840: \"noe's\",\n",
       " 40841: 'quart',\n",
       " 359: 'kids',\n",
       " 5034: 'uplifting',\n",
       " 7093: 'controversy',\n",
       " 21906: 'kida',\n",
       " 23379: 'kidd',\n",
       " 52041: \"error'\",\n",
       " 52042: 'neurologist',\n",
       " 18510: 'spotty',\n",
       " 30570: 'cobblers',\n",
       " 9878: 'projection',\n",
       " 40842: 'fastforwarding',\n",
       " 52043: 'sters',\n",
       " 52044: \"eggar's\",\n",
       " 52045: 'etherything',\n",
       " 40843: 'gateshead',\n",
       " 34708: 'airball',\n",
       " 25244: 'unsinkable',\n",
       " 7180: 'stern',\n",
       " 52046: \"cervi's\",\n",
       " 40844: 'dnd',\n",
       " 11586: 'dna',\n",
       " 20598: 'insecurity',\n",
       " 52047: \"'reboot'\",\n",
       " 11037: 'trelkovsky',\n",
       " 52048: 'jaekel',\n",
       " 52049: 'sidebars',\n",
       " 52050: \"sforza's\",\n",
       " 17633: 'distortions',\n",
       " 52051: 'mutinies',\n",
       " 30602: 'sermons',\n",
       " 40846: '7ft',\n",
       " 52052: 'boobage',\n",
       " 52053: \"o'bannon's\",\n",
       " 23380: 'populations',\n",
       " 52054: 'chulak',\n",
       " 27633: 'mesmerize',\n",
       " 52055: 'quinnell',\n",
       " 10307: 'yahoo',\n",
       " 52057: 'meteorologist',\n",
       " 42577: 'beswick',\n",
       " 15493: 'boorman',\n",
       " 40847: 'voicework',\n",
       " 52058: \"ster'\",\n",
       " 22922: 'blustering',\n",
       " 52059: 'hj',\n",
       " 27634: 'intake',\n",
       " 5621: 'morally',\n",
       " 40849: 'jumbling',\n",
       " 52060: 'bowersock',\n",
       " 52061: \"'porky's'\",\n",
       " 16821: 'gershon',\n",
       " 40850: 'ludicrosity',\n",
       " 52062: 'coprophilia',\n",
       " 40851: 'expressively',\n",
       " 19500: \"india's\",\n",
       " 34710: \"post's\",\n",
       " 52063: 'wana',\n",
       " 5283: 'wang',\n",
       " 30571: 'wand',\n",
       " 25245: 'wane',\n",
       " 52321: 'edgeways',\n",
       " 34711: 'titanium',\n",
       " 40852: 'pinta',\n",
       " 178: 'want',\n",
       " 30572: 'pinto',\n",
       " 52065: 'whoopdedoodles',\n",
       " 21908: 'tchaikovsky',\n",
       " 2103: 'travel',\n",
       " 52066: \"'victory'\",\n",
       " 11928: 'copious',\n",
       " 22433: 'gouge',\n",
       " 52067: \"chapters'\",\n",
       " 6702: 'barbra',\n",
       " 30573: 'uselessness',\n",
       " 52068: \"wan'\",\n",
       " 27635: 'assimilated',\n",
       " 16116: 'petiot',\n",
       " 52069: 'most\\x85and',\n",
       " 3930: 'dinosaurs',\n",
       " 352: 'wrong',\n",
       " 52070: 'seda',\n",
       " 52071: 'stollen',\n",
       " 34712: 'sentencing',\n",
       " 40853: 'ouroboros',\n",
       " 40854: 'assimilates',\n",
       " 40855: 'colorfully',\n",
       " 27636: 'glenne',\n",
       " 52072: 'dongen',\n",
       " 4760: 'subplots',\n",
       " 52073: 'kiloton',\n",
       " 23381: 'chandon',\n",
       " 34713: \"effect'\",\n",
       " 27637: 'snugly',\n",
       " 40856: 'kuei',\n",
       " 9092: 'welcomed',\n",
       " 30071: 'dishonor',\n",
       " 52075: 'concurrence',\n",
       " 23382: 'stoicism',\n",
       " 14896: \"guys'\",\n",
       " 52077: \"beroemd'\",\n",
       " 6703: 'butcher',\n",
       " 40857: \"melfi's\",\n",
       " 30623: 'aargh',\n",
       " 20599: 'playhouse',\n",
       " 11308: 'wickedly',\n",
       " 1180: 'fit',\n",
       " 52078: 'labratory',\n",
       " 40859: 'lifeline',\n",
       " 1927: 'screaming',\n",
       " 4287: 'fix',\n",
       " 52079: 'cineliterate',\n",
       " 52080: 'fic',\n",
       " 52081: 'fia',\n",
       " 34714: 'fig',\n",
       " 52082: 'fmvs',\n",
       " 52083: 'fie',\n",
       " 52084: 'reentered',\n",
       " 30574: 'fin',\n",
       " 52085: 'doctresses',\n",
       " 52086: 'fil',\n",
       " 12606: 'zucker',\n",
       " 31931: 'ached',\n",
       " 52088: 'counsil',\n",
       " 52089: 'paterfamilias',\n",
       " 13885: 'songwriter',\n",
       " 34715: 'shivam',\n",
       " 9654: 'hurting',\n",
       " 299: 'effects',\n",
       " 52090: 'slauther',\n",
       " 52091: \"'flame'\",\n",
       " 52092: 'sommerset',\n",
       " 52093: 'interwhined',\n",
       " 27638: 'whacking',\n",
       " 52094: 'bartok',\n",
       " 8775: 'barton',\n",
       " 21909: 'frewer',\n",
       " 52095: \"fi'\",\n",
       " 6192: 'ingrid',\n",
       " 30575: 'stribor',\n",
       " 52096: 'approporiately',\n",
       " 52097: 'wobblyhand',\n",
       " 52098: 'tantalisingly',\n",
       " 52099: 'ankylosaurus',\n",
       " 17634: 'parasites',\n",
       " 52100: 'childen',\n",
       " 52101: \"jenkins'\",\n",
       " 52102: 'metafiction',\n",
       " 17635: 'golem',\n",
       " 40860: 'indiscretion',\n",
       " 23383: \"reeves'\",\n",
       " 57781: \"inamorata's\",\n",
       " 52104: 'brittannica',\n",
       " 7916: 'adapt',\n",
       " 30576: \"russo's\",\n",
       " 48246: 'guitarists',\n",
       " 10553: 'abbott',\n",
       " 40861: 'abbots',\n",
       " 17649: 'lanisha',\n",
       " 40863: 'magickal',\n",
       " 52105: 'mattter',\n",
       " 52106: \"'willy\",\n",
       " 34716: 'pumpkins',\n",
       " 52107: 'stuntpeople',\n",
       " 30577: 'estimate',\n",
       " 40864: 'ugghhh',\n",
       " 11309: 'gameplay',\n",
       " 52108: \"wern't\",\n",
       " 40865: \"n'sync\",\n",
       " 16117: 'sickeningly',\n",
       " 40866: 'chiara',\n",
       " 4011: 'disturbed',\n",
       " 40867: 'portmanteau',\n",
       " 52109: 'ineffectively',\n",
       " 82143: \"duchonvey's\",\n",
       " 37519: \"nasty'\",\n",
       " 1285: 'purpose',\n",
       " 52112: 'lazers',\n",
       " 28105: 'lightened',\n",
       " 52113: 'kaliganj',\n",
       " 52114: 'popularism',\n",
       " 18511: \"damme's\",\n",
       " 30578: 'stylistics',\n",
       " 52115: 'mindgaming',\n",
       " 46449: 'spoilerish',\n",
       " 52117: \"'corny'\",\n",
       " 34718: 'boerner',\n",
       " 6792: 'olds',\n",
       " 52118: 'bakelite',\n",
       " 27639: 'renovated',\n",
       " 27640: 'forrester',\n",
       " 52119: \"lumiere's\",\n",
       " 52024: 'gaskets',\n",
       " 884: 'needed',\n",
       " 34719: 'smight',\n",
       " 1297: 'master',\n",
       " 25905: \"edie's\",\n",
       " 40868: 'seeber',\n",
       " 52120: 'hiya',\n",
       " 52121: 'fuzziness',\n",
       " 14897: 'genesis',\n",
       " 12607: 'rewards',\n",
       " 30579: 'enthrall',\n",
       " 40869: \"'about\",\n",
       " 52122: \"recollection's\",\n",
       " 11039: 'mutilated',\n",
       " 52123: 'fatherlands',\n",
       " 52124: \"fischer's\",\n",
       " 5399: 'positively',\n",
       " 34705: '270',\n",
       " 34720: 'ahmed',\n",
       " 9836: 'zatoichi',\n",
       " 13886: 'bannister',\n",
       " 52127: 'anniversaries',\n",
       " 30580: \"helm's\",\n",
       " 52128: \"'work'\",\n",
       " 34721: 'exclaimed',\n",
       " 52129: \"'unfunny'\",\n",
       " 52029: '274',\n",
       " 544: 'feeling',\n",
       " 52131: \"wanda's\",\n",
       " 33266: 'dolan',\n",
       " 52133: '278',\n",
       " 52134: 'peacoat',\n",
       " 40870: 'brawny',\n",
       " 40871: 'mishra',\n",
       " 40872: 'worlders',\n",
       " 52135: 'protags',\n",
       " 52136: 'skullcap',\n",
       " 57596: 'dastagir',\n",
       " 5622: 'affairs',\n",
       " 7799: 'wholesome',\n",
       " 52137: 'hymen',\n",
       " 25246: 'paramedics',\n",
       " 52138: 'unpersons',\n",
       " 52139: 'heavyarms',\n",
       " 52140: 'affaire',\n",
       " 52141: 'coulisses',\n",
       " 40873: 'hymer',\n",
       " 52142: 'kremlin',\n",
       " 30581: 'shipments',\n",
       " 52143: 'pixilated',\n",
       " 30582: \"'00s\",\n",
       " 18512: 'diminishing',\n",
       " 1357: 'cinematic',\n",
       " 14898: 'resonates',\n",
       " 40874: 'simplify',\n",
       " 40875: \"nature'\",\n",
       " 40876: 'temptresses',\n",
       " 16822: 'reverence',\n",
       " 19502: 'resonated',\n",
       " 34722: 'dailey',\n",
       " 52144: '2\\x85',\n",
       " 27641: 'treize',\n",
       " 52145: 'majo',\n",
       " 21910: 'kiya',\n",
       " 52146: 'woolnough',\n",
       " 39797: 'thanatos',\n",
       " 35731: 'sandoval',\n",
       " 40879: 'dorama',\n",
       " 52147: \"o'shaughnessy\",\n",
       " 4988: 'tech',\n",
       " 32018: 'fugitives',\n",
       " 30583: 'teck',\n",
       " 76125: \"'e'\",\n",
       " 40881: 'doesn’t',\n",
       " 52149: 'purged',\n",
       " 657: 'saying',\n",
       " 41095: \"martians'\",\n",
       " 23418: 'norliss',\n",
       " 27642: 'dickey',\n",
       " 52152: 'dicker',\n",
       " 52153: \"'sependipity\",\n",
       " 8422: 'padded',\n",
       " 57792: 'ordell',\n",
       " 40882: \"sturges'\",\n",
       " 52154: 'independentcritics',\n",
       " 5745: 'tempted',\n",
       " 34724: \"atkinson's\",\n",
       " 25247: 'hounded',\n",
       " 52155: 'apace',\n",
       " 15494: 'clicked',\n",
       " 30584: \"'humor'\",\n",
       " 17177: \"martino's\",\n",
       " 52156: \"'supporting\",\n",
       " 52032: 'warmongering',\n",
       " 34725: \"zemeckis's\",\n",
       " 21911: 'lube',\n",
       " 52157: 'shocky',\n",
       " 7476: 'plate',\n",
       " 40883: 'plata',\n",
       " 40884: 'sturgess',\n",
       " 40885: \"nerds'\",\n",
       " 20600: 'plato',\n",
       " 34726: 'plath',\n",
       " 40886: 'platt',\n",
       " 52159: 'mcnab',\n",
       " 27643: 'clumsiness',\n",
       " 3899: 'altogether',\n",
       " 42584: 'massacring',\n",
       " 52160: 'bicenntinial',\n",
       " 40887: 'skaal',\n",
       " 14360: 'droning',\n",
       " 8776: 'lds',\n",
       " 21912: 'jaguar',\n",
       " 34727: \"cale's\",\n",
       " 1777: 'nicely',\n",
       " 4588: 'mummy',\n",
       " 18513: \"lot's\",\n",
       " 10086: 'patch',\n",
       " 50202: 'kerkhof',\n",
       " 52161: \"leader's\",\n",
       " 27644: \"'movie\",\n",
       " 52162: 'uncomfirmed',\n",
       " 40888: 'heirloom',\n",
       " 47360: 'wrangle',\n",
       " 52163: 'emotion\\x85',\n",
       " 52164: \"'stargate'\",\n",
       " 40889: 'pinoy',\n",
       " 40890: 'conchatta',\n",
       " 41128: 'broeke',\n",
       " 40891: 'advisedly',\n",
       " 17636: \"barker's\",\n",
       " 52166: 'descours',\n",
       " 772: 'lots',\n",
       " 9259: 'lotr',\n",
       " 9879: 'irs',\n",
       " 52167: 'lott',\n",
       " 40892: 'xvi',\n",
       " 34728: 'irk',\n",
       " 52168: 'irl',\n",
       " 6887: 'ira',\n",
       " 21913: 'belzer',\n",
       " 52169: 'irc',\n",
       " 27645: 'ire',\n",
       " 40893: 'requisites',\n",
       " 7693: 'discipline',\n",
       " 52961: 'lyoko',\n",
       " 11310: 'extend',\n",
       " 873: 'nature',\n",
       " 52170: \"'dickie'\",\n",
       " 40894: 'optimist',\n",
       " 30586: 'lapping',\n",
       " 3900: 'superficial',\n",
       " 52171: 'vestment',\n",
       " 2823: 'extent',\n",
       " 52172: 'tendons',\n",
       " 52173: \"heller's\",\n",
       " 52174: 'quagmires',\n",
       " 52175: 'miyako',\n",
       " 20601: 'moocow',\n",
       " 52176: \"coles'\",\n",
       " 40895: 'lookit',\n",
       " 52177: 'ravenously',\n",
       " 40896: 'levitating',\n",
       " 52178: 'perfunctorily',\n",
       " 30587: 'lookin',\n",
       " 40898: \"lot'\",\n",
       " 52179: 'lookie',\n",
       " 34870: 'fearlessly',\n",
       " 52181: 'libyan',\n",
       " 40899: 'fondles',\n",
       " 35714: 'gopher',\n",
       " 40901: 'wearying',\n",
       " 52182: \"nz's\",\n",
       " 27646: 'minuses',\n",
       " 52183: 'puposelessly',\n",
       " 52184: 'shandling',\n",
       " 31268: 'decapitates',\n",
       " 11929: 'humming',\n",
       " 40902: \"'nother\",\n",
       " 21914: 'smackdown',\n",
       " 30588: 'underdone',\n",
       " 40903: 'frf',\n",
       " 52185: 'triviality',\n",
       " 25248: 'fro',\n",
       " 8777: 'bothers',\n",
       " 52186: \"'kensington\",\n",
       " 73: 'much',\n",
       " 34730: 'muco',\n",
       " 22615: 'wiseguy',\n",
       " 27648: \"richie's\",\n",
       " 40904: 'tonino',\n",
       " 52187: 'unleavened',\n",
       " 11587: 'fry',\n",
       " 40905: \"'tv'\",\n",
       " 40906: 'toning',\n",
       " 14361: 'obese',\n",
       " 30589: 'sensationalized',\n",
       " 40907: 'spiv',\n",
       " 6259: 'spit',\n",
       " 7364: 'arkin',\n",
       " 21915: 'charleton',\n",
       " 16823: 'jeon',\n",
       " 21916: 'boardroom',\n",
       " 4989: 'doubts',\n",
       " 3084: 'spin',\n",
       " 53083: 'hepo',\n",
       " 27649: 'wildcat',\n",
       " 10584: 'venoms',\n",
       " 52191: 'misconstrues',\n",
       " 18514: 'mesmerising',\n",
       " 40908: 'misconstrued',\n",
       " 52192: 'rescinds',\n",
       " 52193: 'prostrate',\n",
       " 40909: 'majid',\n",
       " 16479: 'climbed',\n",
       " 34731: 'canoeing',\n",
       " 52195: 'majin',\n",
       " 57804: 'animie',\n",
       " 40910: 'sylke',\n",
       " 14899: 'conditioned',\n",
       " 40911: 'waddell',\n",
       " 52196: '3\\x85',\n",
       " 41188: 'hyperdrive',\n",
       " 34732: 'conditioner',\n",
       " 53153: 'bricklayer',\n",
       " 2576: 'hong',\n",
       " 52198: 'memoriam',\n",
       " 30592: 'inventively',\n",
       " 25249: \"levant's\",\n",
       " 20638: 'portobello',\n",
       " 52200: 'remand',\n",
       " 19504: 'mummified',\n",
       " 27650: 'honk',\n",
       " 19505: 'spews',\n",
       " 40912: 'visitations',\n",
       " 52201: 'mummifies',\n",
       " 25250: 'cavanaugh',\n",
       " 23385: 'zeon',\n",
       " 40913: \"jungle's\",\n",
       " 34733: 'viertel',\n",
       " 27651: 'frenchmen',\n",
       " 52202: 'torpedoes',\n",
       " 52203: 'schlessinger',\n",
       " 34734: 'torpedoed',\n",
       " 69876: 'blister',\n",
       " 52204: 'cinefest',\n",
       " 34735: 'furlough',\n",
       " 52205: 'mainsequence',\n",
       " 40914: 'mentors',\n",
       " 9094: 'academic',\n",
       " 20602: 'stillness',\n",
       " 40915: 'academia',\n",
       " 52206: 'lonelier',\n",
       " 52207: 'nibby',\n",
       " 52208: \"losers'\",\n",
       " 40916: 'cineastes',\n",
       " 4449: 'corporate',\n",
       " 40917: 'massaging',\n",
       " 30593: 'bellow',\n",
       " 19506: 'absurdities',\n",
       " 53241: 'expetations',\n",
       " 40918: 'nyfiken',\n",
       " 75638: 'mehras',\n",
       " 52209: 'lasse',\n",
       " 52210: 'visability',\n",
       " 33946: 'militarily',\n",
       " 52211: \"elder'\",\n",
       " 19023: 'gainsbourg',\n",
       " 20603: 'hah',\n",
       " 13420: 'hai',\n",
       " 34736: 'haj',\n",
       " 25251: 'hak',\n",
       " 4311: 'hal',\n",
       " 4892: 'ham',\n",
       " 53259: 'duffer',\n",
       " 52213: 'haa',\n",
       " 66: 'had',\n",
       " 11930: 'advancement',\n",
       " 16825: 'hag',\n",
       " 25252: \"hand'\",\n",
       " 13421: 'hay',\n",
       " 20604: 'mcnamara',\n",
       " 52214: \"mozart's\",\n",
       " 30731: 'duffel',\n",
       " 30594: 'haq',\n",
       " 13887: 'har',\n",
       " 44: 'has',\n",
       " 2401: 'hat',\n",
       " 40919: 'hav',\n",
       " 30595: 'haw',\n",
       " 52215: 'figtings',\n",
       " 15495: 'elders',\n",
       " 52216: 'underpanted',\n",
       " 52217: 'pninson',\n",
       " 27652: 'unequivocally',\n",
       " 23673: \"barbara's\",\n",
       " 52219: \"bello'\",\n",
       " 12997: 'indicative',\n",
       " 40920: 'yawnfest',\n",
       " 52220: 'hexploitation',\n",
       " 52221: \"loder's\",\n",
       " 27653: 'sleuthing',\n",
       " 32622: \"justin's\",\n",
       " 52222: \"'ball\",\n",
       " 52223: \"'summer\",\n",
       " 34935: \"'demons'\",\n",
       " 52225: \"mormon's\",\n",
       " 34737: \"laughton's\",\n",
       " 52226: 'debell',\n",
       " 39724: 'shipyard',\n",
       " 30597: 'unabashedly',\n",
       " 40401: 'disks',\n",
       " 2290: 'crowd',\n",
       " 10087: 'crowe',\n",
       " 56434: \"vancouver's\",\n",
       " 34738: 'mosques',\n",
       " 6627: 'crown',\n",
       " 52227: 'culpas',\n",
       " 27654: 'crows',\n",
       " 53344: 'surrell',\n",
       " 52229: 'flowless',\n",
       " 52230: 'sheirk',\n",
       " 40923: \"'three\",\n",
       " 52231: \"peterson'\",\n",
       " 52232: 'ooverall',\n",
       " 40924: 'perchance',\n",
       " 1321: 'bottom',\n",
       " 53363: 'chabert',\n",
       " 52233: 'sneha',\n",
       " 13888: 'inhuman',\n",
       " 52234: 'ichii',\n",
       " 52235: 'ursla',\n",
       " 30598: 'completly',\n",
       " 40925: 'moviedom',\n",
       " 52236: 'raddick',\n",
       " 51995: 'brundage',\n",
       " 40926: 'brigades',\n",
       " 1181: 'starring',\n",
       " 52237: \"'goal'\",\n",
       " 52238: 'caskets',\n",
       " 52239: 'willcock',\n",
       " 52240: \"threesome's\",\n",
       " 52241: \"mosque'\",\n",
       " 52242: \"cover's\",\n",
       " 17637: 'spaceships',\n",
       " 40927: 'anomalous',\n",
       " 27655: 'ptsd',\n",
       " 52243: 'shirdan',\n",
       " 21962: 'obscenity',\n",
       " 30599: 'lemmings',\n",
       " 30600: 'duccio',\n",
       " 52244: \"levene's\",\n",
       " 52245: \"'gorby'\",\n",
       " 25255: \"teenager's\",\n",
       " 5340: 'marshall',\n",
       " 9095: 'honeymoon',\n",
       " 3231: 'shoots',\n",
       " 12258: 'despised',\n",
       " 52246: 'okabasho',\n",
       " 8289: 'fabric',\n",
       " 18515: 'cannavale',\n",
       " 3537: 'raped',\n",
       " 52247: \"tutt's\",\n",
       " 17638: 'grasping',\n",
       " 18516: 'despises',\n",
       " 40928: \"thief's\",\n",
       " 8926: 'rapes',\n",
       " 52248: 'raper',\n",
       " 27656: \"eyre'\",\n",
       " 52249: 'walchek',\n",
       " 23386: \"elmo's\",\n",
       " 40929: 'perfumes',\n",
       " 21918: 'spurting',\n",
       " 52250: \"exposition'\\x85\",\n",
       " 52251: 'denoting',\n",
       " 34740: 'thesaurus',\n",
       " 40930: \"shoot'\",\n",
       " 49759: 'bonejack',\n",
       " 52253: 'simpsonian',\n",
       " 30601: 'hebetude',\n",
       " 34741: \"hallow's\",\n",
       " 52254: 'desperation\\x85',\n",
       " 34742: 'incinerator',\n",
       " 10308: 'congratulations',\n",
       " 52255: 'humbled',\n",
       " 5924: \"else's\",\n",
       " 40845: 'trelkovski',\n",
       " 52256: \"rape'\",\n",
       " 59386: \"'chapters'\",\n",
       " 52257: '1600s',\n",
       " 7253: 'martian',\n",
       " 25256: 'nicest',\n",
       " 52259: 'eyred',\n",
       " 9457: 'passenger',\n",
       " 6041: 'disgrace',\n",
       " 52260: 'moderne',\n",
       " 5120: 'barrymore',\n",
       " 52261: 'yankovich',\n",
       " 40931: 'moderns',\n",
       " 52262: 'studliest',\n",
       " 52263: 'bedsheet',\n",
       " 14900: 'decapitation',\n",
       " 52264: 'slurring',\n",
       " 52265: \"'nunsploitation'\",\n",
       " 34743: \"'character'\",\n",
       " 9880: 'cambodia',\n",
       " 52266: 'rebelious',\n",
       " 27657: 'pasadena',\n",
       " 40932: 'crowne',\n",
       " 52267: \"'bedchamber\",\n",
       " 52268: 'conjectural',\n",
       " 52269: 'appologize',\n",
       " 52270: 'halfassing',\n",
       " 57816: 'paycheque',\n",
       " 20606: 'palms',\n",
       " 52271: \"'islands\",\n",
       " 40933: 'hawked',\n",
       " 21919: 'palme',\n",
       " 40934: 'conservatively',\n",
       " 64007: 'larp',\n",
       " 5558: 'palma',\n",
       " 21920: 'smelling',\n",
       " 12998: 'aragorn',\n",
       " 52272: 'hawker',\n",
       " 52273: 'hawkes',\n",
       " 3975: 'explosions',\n",
       " 8059: 'loren',\n",
       " 52274: \"pyle's\",\n",
       " 6704: 'shootout',\n",
       " 18517: \"mike's\",\n",
       " 52275: \"driscoll's\",\n",
       " 40935: 'cogsworth',\n",
       " 52276: \"britian's\",\n",
       " 34744: 'childs',\n",
       " 52277: \"portrait's\",\n",
       " 3626: 'chain',\n",
       " 2497: 'whoever',\n",
       " 52278: 'puttered',\n",
       " 52279: 'childe',\n",
       " 52280: 'maywether',\n",
       " 3036: 'chair',\n",
       " 52281: \"rance's\",\n",
       " 34745: 'machu',\n",
       " 4517: 'ballet',\n",
       " 34746: 'grapples',\n",
       " 76152: 'summerize',\n",
       " 30603: 'freelance',\n",
       " 52283: \"andrea's\",\n",
       " 52284: '\\x91very',\n",
       " 45879: 'coolidge',\n",
       " 18518: 'mache',\n",
       " 52285: 'balled',\n",
       " 40937: 'grappled',\n",
       " 18519: 'macha',\n",
       " 21921: 'underlining',\n",
       " 5623: 'macho',\n",
       " 19507: 'oversight',\n",
       " 25257: 'machi',\n",
       " 11311: 'verbally',\n",
       " 21922: 'tenacious',\n",
       " 40938: 'windshields',\n",
       " 18557: 'paychecks',\n",
       " 3396: 'jerk',\n",
       " 11931: \"good'\",\n",
       " 34748: 'prancer',\n",
       " 21923: 'prances',\n",
       " 52286: 'olympus',\n",
       " 21924: 'lark',\n",
       " 10785: 'embark',\n",
       " 7365: 'gloomy',\n",
       " 52287: 'jehaan',\n",
       " 52288: 'turaqui',\n",
       " 20607: \"child'\",\n",
       " 2894: 'locked',\n",
       " 52289: 'pranced',\n",
       " 2588: 'exact',\n",
       " 52290: 'unattuned',\n",
       " 783: 'minute',\n",
       " 16118: 'skewed',\n",
       " 40940: 'hodgins',\n",
       " 34749: 'skewer',\n",
       " 52291: 'think\\x85',\n",
       " 38765: 'rosenstein',\n",
       " 52292: 'helmit',\n",
       " 34750: 'wrestlemanias',\n",
       " 16826: 'hindered',\n",
       " 30604: \"martha's\",\n",
       " 52293: 'cheree',\n",
       " 52294: \"pluckin'\",\n",
       " 40941: 'ogles',\n",
       " 11932: 'heavyweight',\n",
       " 82190: 'aada',\n",
       " 11312: 'chopping',\n",
       " 61534: 'strongboy',\n",
       " 41342: 'hegemonic',\n",
       " 40942: 'adorns',\n",
       " 41346: 'xxth',\n",
       " 34751: 'nobuhiro',\n",
       " 52298: 'capitães',\n",
       " 52299: 'kavogianni',\n",
       " 13422: 'antwerp',\n",
       " 6538: 'celebrated',\n",
       " 52300: 'roarke',\n",
       " 40943: 'baggins',\n",
       " 31270: 'cheeseburgers',\n",
       " 52301: 'matras',\n",
       " 52302: \"nineties'\",\n",
       " 52303: \"'craig'\",\n",
       " 12999: 'celebrates',\n",
       " 3383: 'unintentionally',\n",
       " 14362: 'drafted',\n",
       " 52304: 'climby',\n",
       " 52305: '303',\n",
       " 18520: 'oldies',\n",
       " 9096: 'climbs',\n",
       " 9655: 'honour',\n",
       " 34752: 'plucking',\n",
       " 30074: '305',\n",
       " 5514: 'address',\n",
       " 40944: 'menjou',\n",
       " 42592: \"'freak'\",\n",
       " 19508: 'dwindling',\n",
       " 9458: 'benson',\n",
       " 52307: 'white’s',\n",
       " 40945: 'shamelessness',\n",
       " 21925: 'impacted',\n",
       " 52308: 'upatz',\n",
       " 3840: 'cusack',\n",
       " 37567: \"flavia's\",\n",
       " 52309: 'effette',\n",
       " 34753: 'influx',\n",
       " 52310: 'boooooooo',\n",
       " 52311: 'dimitrova',\n",
       " 13423: 'houseman',\n",
       " 25259: 'bigas',\n",
       " 52312: 'boylen',\n",
       " 52313: 'phillipenes',\n",
       " 40946: 'fakery',\n",
       " 27658: \"grandpa's\",\n",
       " 27659: 'darnell',\n",
       " 19509: 'undergone',\n",
       " 52315: 'handbags',\n",
       " 21926: 'perished',\n",
       " 37778: 'pooped',\n",
       " 27660: 'vigour',\n",
       " 3627: 'opposed',\n",
       " 52316: 'etude',\n",
       " 11799: \"caine's\",\n",
       " 52317: 'doozers',\n",
       " 34754: 'photojournals',\n",
       " 52318: 'perishes',\n",
       " 34755: 'constrains',\n",
       " 40948: 'migenes',\n",
       " 30605: 'consoled',\n",
       " 16827: 'alastair',\n",
       " 52319: 'wvs',\n",
       " 52320: 'ooooooh',\n",
       " 34756: 'approving',\n",
       " 40949: 'consoles',\n",
       " 52064: 'disparagement',\n",
       " 52322: 'futureistic',\n",
       " 52323: 'rebounding',\n",
       " 52324: \"'date\",\n",
       " 52325: 'gregoire',\n",
       " 21927: 'rutherford',\n",
       " 34757: 'americanised',\n",
       " 82196: 'novikov',\n",
       " 1042: 'following',\n",
       " 34758: 'munroe',\n",
       " 52326: \"morita'\",\n",
       " 52327: 'christenssen',\n",
       " 23106: 'oatmeal',\n",
       " 25260: 'fossey',\n",
       " 40950: 'livered',\n",
       " 13000: 'listens',\n",
       " 76164: \"'marci\",\n",
       " 52330: \"otis's\",\n",
       " 23387: 'thanking',\n",
       " 16019: 'maude',\n",
       " 34759: 'extensions',\n",
       " 52332: 'ameteurish',\n",
       " 52333: \"commender's\",\n",
       " 27661: 'agricultural',\n",
       " 4518: 'convincingly',\n",
       " 17639: 'fueled',\n",
       " 54014: 'mahattan',\n",
       " 40952: \"paris's\",\n",
       " 52336: 'vulkan',\n",
       " 52337: 'stapes',\n",
       " 52338: 'odysessy',\n",
       " 12259: 'harmon',\n",
       " 4252: 'surfing',\n",
       " 23494: 'halloran',\n",
       " 49580: 'unbelieveably',\n",
       " 52339: \"'offed'\",\n",
       " 30607: 'quadrant',\n",
       " 19510: 'inhabiting',\n",
       " 34760: 'nebbish',\n",
       " 40953: 'forebears',\n",
       " 34761: 'skirmish',\n",
       " 52340: 'ocassionally',\n",
       " 52341: \"'resist\",\n",
       " 21928: 'impactful',\n",
       " 52342: 'spicier',\n",
       " 40954: 'touristy',\n",
       " 52343: \"'football'\",\n",
       " 40955: 'webpage',\n",
       " 52345: 'exurbia',\n",
       " 52346: 'jucier',\n",
       " 14901: 'professors',\n",
       " 34762: 'structuring',\n",
       " 30608: 'jig',\n",
       " 40956: 'overlord',\n",
       " 25261: 'disconnect',\n",
       " 82201: 'sniffle',\n",
       " 40957: 'slimeball',\n",
       " 40958: 'jia',\n",
       " 16828: 'milked',\n",
       " 40959: 'banjoes',\n",
       " 1237: 'jim',\n",
       " 52348: 'workforces',\n",
       " 52349: 'jip',\n",
       " 52350: 'rotweiller',\n",
       " 34763: 'mundaneness',\n",
       " 52351: \"'ninja'\",\n",
       " 11040: \"dead'\",\n",
       " 40960: \"cipriani's\",\n",
       " 20608: 'modestly',\n",
       " 52352: \"professor'\",\n",
       " 40961: 'shacked',\n",
       " 34764: 'bashful',\n",
       " 23388: 'sorter',\n",
       " 16120: 'overpowering',\n",
       " 18521: 'workmanlike',\n",
       " 27662: 'henpecked',\n",
       " 18522: 'sorted',\n",
       " 52354: \"jōb's\",\n",
       " 52355: \"'always\",\n",
       " 34765: \"'baptists\",\n",
       " 52356: 'dreamcatchers',\n",
       " 52357: \"'silence'\",\n",
       " 21929: 'hickory',\n",
       " 52358: 'fun\\x97yet',\n",
       " 52359: 'breakumentary',\n",
       " 15496: 'didn',\n",
       " 52360: 'didi',\n",
       " 52361: 'pealing',\n",
       " 40962: 'dispite',\n",
       " 25262: \"italy's\",\n",
       " 21930: 'instability',\n",
       " 6539: 'quarter',\n",
       " 12608: 'quartet',\n",
       " 52362: 'padmé',\n",
       " 52363: \"'bleedmedry\",\n",
       " 52364: 'pahalniuk',\n",
       " 52365: 'honduras',\n",
       " 10786: 'bursting',\n",
       " 41465: \"pablo's\",\n",
       " 52367: 'irremediably',\n",
       " 40963: 'presages',\n",
       " 57832: 'bowlegged',\n",
       " 65183: 'dalip',\n",
       " 6260: 'entering',\n",
       " 76172: 'newsradio',\n",
       " 54150: 'presaged',\n",
       " 27663: \"giallo's\",\n",
       " 40964: 'bouyant',\n",
       " 52368: 'amerterish',\n",
       " 18523: 'rajni',\n",
       " 30610: 'leeves',\n",
       " 34767: 'macauley',\n",
       " 612: 'seriously',\n",
       " 52369: 'sugercoma',\n",
       " 52370: 'grimstead',\n",
       " 52371: \"'fairy'\",\n",
       " 30611: 'zenda',\n",
       " 52372: \"'twins'\",\n",
       " 17640: 'realisation',\n",
       " 27664: 'highsmith',\n",
       " 7817: 'raunchy',\n",
       " 40965: 'incentives',\n",
       " 52374: 'flatson',\n",
       " 35097: 'snooker',\n",
       " 16829: 'crazies',\n",
       " 14902: 'crazier',\n",
       " 7094: 'grandma',\n",
       " 52375: 'napunsaktha',\n",
       " 30612: 'workmanship',\n",
       " 52376: 'reisner',\n",
       " 61306: \"sanford's\",\n",
       " 52377: '\\x91doña',\n",
       " 6108: 'modest',\n",
       " 19153: \"everything's\",\n",
       " 40966: 'hamer',\n",
       " 52379: \"couldn't'\",\n",
       " 13001: 'quibble',\n",
       " 52380: 'socking',\n",
       " 21931: 'tingler',\n",
       " 52381: 'gutman',\n",
       " 40967: 'lachlan',\n",
       " 52382: 'tableaus',\n",
       " 52383: 'headbanger',\n",
       " 2847: 'spoken',\n",
       " 34768: 'cerebrally',\n",
       " 23490: \"'road\",\n",
       " 21932: 'tableaux',\n",
       " 40968: \"proust's\",\n",
       " 40969: 'periodical',\n",
       " 52385: \"shoveller's\",\n",
       " 25263: 'tamara',\n",
       " 17641: 'affords',\n",
       " 3249: 'concert',\n",
       " 87955: \"yara's\",\n",
       " 52386: 'someome',\n",
       " 8424: 'lingering',\n",
       " 41511: \"abraham's\",\n",
       " 34769: 'beesley',\n",
       " 34770: 'cherbourg',\n",
       " 28624: 'kagan',\n",
       " 9097: 'snatch',\n",
       " 9260: \"miyazaki's\",\n",
       " 25264: 'absorbs',\n",
       " 40970: \"koltai's\",\n",
       " 64027: 'tingled',\n",
       " 19511: 'crossroads',\n",
       " 16121: 'rehab',\n",
       " 52389: 'falworth',\n",
       " 52390: 'sequals',\n",
       " ...}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just checking for training data after joining words after mapping word with its index \n",
    "' '.join([index_word_dict[index] for index in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encodes words into vector\n",
    "train_data = vectorize_sequences(train_data)\n",
    "test_data = vectorize_sequences(test_data)\n",
    "\n",
    "# Splits data training and validation data sets\n",
    "validation_data = train_data[15000:]\n",
    "train_data = train_data[0:15000]\n",
    "\n",
    "train_labels = train_labels.astype(dtype='float32')\n",
    "# train_labels = np.asarray(train_labels).astype('float32')\n",
    "test_labels = test_labels.astype(dtype='float32')\n",
    "# test_labels = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "validation_labels = train_labels[15000:]\n",
    "train_labels = train_labels[0:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.5343 - accuracy: 0.7784 - val_loss: 0.4031 - val_accuracy: 0.8634\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.3249 - accuracy: 0.8995 - val_loss: 0.3128 - val_accuracy: 0.8892\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.2377 - accuracy: 0.9255 - val_loss: 0.2828 - val_accuracy: 0.8943\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.1858 - accuracy: 0.9423 - val_loss: 0.2838 - val_accuracy: 0.8861\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1516 - accuracy: 0.9519 - val_loss: 0.2841 - val_accuracy: 0.8888\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.1248 - accuracy: 0.9627 - val_loss: 0.2878 - val_accuracy: 0.8875\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.1023 - accuracy: 0.9703 - val_loss: 0.3151 - val_accuracy: 0.8814\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0850 - accuracy: 0.9774 - val_loss: 0.3231 - val_accuracy: 0.8824\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0701 - accuracy: 0.9825 - val_loss: 0.4309 - val_accuracy: 0.8600\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 43us/step - loss: 0.0602 - accuracy: 0.9847 - val_loss: 0.3793 - val_accuracy: 0.8736\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.0469 - accuracy: 0.9889 - val_loss: 0.3946 - val_accuracy: 0.8768\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0402 - accuracy: 0.9905 - val_loss: 0.4261 - val_accuracy: 0.8751\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 0.5012 - val_accuracy: 0.8625\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0237 - accuracy: 0.9964 - val_loss: 0.5109 - val_accuracy: 0.8663\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0226 - accuracy: 0.9964 - val_loss: 0.5133 - val_accuracy: 0.8707\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.5430 - val_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s 37us/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.5757 - val_accuracy: 0.8691\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.6213 - val_accuracy: 0.8669\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 43us/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.6483 - val_accuracy: 0.8653\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s 46us/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.7829 - val_accuracy: 0.8575\n"
     ]
    }
   ],
   "source": [
    "# Trains model with bath size of 512 and 20 epochs\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=20, \n",
    "                    validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluates training and validation performance\n",
    "history_dict = history.history\n",
    "\n",
    "epochs = range(1, len(history_dict[\"accuracy\"]) + 1)\n",
    "validation_losses = history_dict[\"val_loss\"]\n",
    "training_losses = history_dict[\"loss\"]\n",
    "\n",
    "plt.plot(epochs, validation_losses, \"b\", label=\"Validation Loss\")\n",
    "plt.plot(epochs, training_losses, \"bo\", label=\"Training Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_accuracies = history_dict[\"accuracy\"]\n",
    "validation_accuracies = history_dict[\"val_accuracy\"]\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(epochs, training_accuracies, 'bo', label=\"Training Accuracy\")\n",
    "plt.plot(epochs, validation_accuracies, 'b', label=\"Validation Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.7270 - val_accuracy: 0.8647\n",
      "Epoch 2/4\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.7634 - val_accuracy: 0.8636\n",
      "Epoch 3/4\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.8134 - val_accuracy: 0.8643\n",
      "Epoch 4/4\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.8389 - val_accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "# Observing overfitting beyond 4 epochs, model is retrained with 4 epoch only.\n",
    "\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=4, \n",
    "                    validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 55us/step\n",
      "Model Performance on Test Data: Loss is  0.9150699216455221  and accuracy is  0.8450400233268738\n"
     ]
    }
   ],
   "source": [
    "# Evaluates testing performance\n",
    "evaluation = model.evaluate(test_data, test_labels)\n",
    "print(\"Model Performance on Test Data: Loss is \", evaluation[0], \" and accuracy is \", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9205930e-03],\n",
       "       [9.9999988e-01],\n",
       "       [1.1920929e-07],\n",
       "       ...,\n",
       "       [4.5494694e-01],\n",
       "       [5.1259995e-05],\n",
       "       [5.5426657e-03]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting reviews\n",
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, consider the above model is baselined and let's experiment with different number hiddent layers, hidden units, optimizers and activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing and decreasing hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing hidden layers from 2 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "15000/15000 [==============================] - 1s 52us/step - loss: 0.5462 - accuracy: 0.7620 - val_loss: 0.4023 - val_accuracy: 0.8674\n",
      "Epoch 2/6\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.3162 - accuracy: 0.9014 - val_loss: 0.3060 - val_accuracy: 0.8859\n",
      "Epoch 3/6\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.2218 - accuracy: 0.9258 - val_loss: 0.2882 - val_accuracy: 0.8851\n",
      "Epoch 4/6\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1678 - accuracy: 0.9455 - val_loss: 0.2790 - val_accuracy: 0.8877\n",
      "Epoch 5/6\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1330 - accuracy: 0.9557 - val_loss: 0.3118 - val_accuracy: 0.8826\n",
      "Epoch 6/6\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1028 - accuracy: 0.9677 - val_loss: 0.3170 - val_accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "# Creates model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=6, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 53us/step\n",
      "Model Performance on Test Data: Loss is  0.34693423069953916  and accuracy is  0.8737199902534485\n"
     ]
    }
   ],
   "source": [
    "# Evaluates testing performance\n",
    "evaluation = model.evaluate(test_data, test_labels)\n",
    "print(\"Model Performance on Test Data: Loss is \", evaluation[0], \" and accuracy is \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decreasing hidden layers from 2 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "15000/15000 [==============================] - 1s 51us/step - loss: 0.4989 - accuracy: 0.7941 - val_loss: 0.3907 - val_accuracy: 0.8659\n",
      "Epoch 2/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.3152 - accuracy: 0.9054 - val_loss: 0.3207 - val_accuracy: 0.8814\n",
      "Epoch 3/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.2448 - accuracy: 0.9229 - val_loss: 0.3078 - val_accuracy: 0.8801\n",
      "Epoch 4/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.1999 - accuracy: 0.9392 - val_loss: 0.2760 - val_accuracy: 0.8938\n",
      "Epoch 5/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.1686 - accuracy: 0.9503 - val_loss: 0.2748 - val_accuracy: 0.8918\n",
      "Epoch 6/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.1459 - accuracy: 0.9573 - val_loss: 0.2785 - val_accuracy: 0.8896\n"
     ]
    }
   ],
   "source": [
    "# Creates model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=6, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 54us/step\n",
      "Model Performance on Test Data: Loss is  0.30089749811172484  and accuracy is  0.8781200051307678\n"
     ]
    }
   ],
   "source": [
    "# Evaluates testing performance\n",
    "evaluation = model.evaluate(test_data, test_labels)\n",
    "print(\"Model Performance on Test Data: Loss is \", evaluation[0], \" and accuracy is \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing and decreasing hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing hidden units from 16 to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "15000/15000 [==============================] - 1s 62us/step - loss: 0.5031 - accuracy: 0.7781 - val_loss: 0.3566 - val_accuracy: 0.8782\n",
      "Epoch 2/6\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.2825 - accuracy: 0.9042 - val_loss: 0.2884 - val_accuracy: 0.8921\n",
      "Epoch 3/6\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.2048 - accuracy: 0.9304 - val_loss: 0.2755 - val_accuracy: 0.8933\n",
      "Epoch 4/6\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.1578 - accuracy: 0.9485 - val_loss: 0.3075 - val_accuracy: 0.8763\n",
      "Epoch 5/6\n",
      "15000/15000 [==============================] - 1s 48us/step - loss: 0.1250 - accuracy: 0.9591 - val_loss: 0.3065 - val_accuracy: 0.8841\n",
      "Epoch 6/6\n",
      "15000/15000 [==============================] - 1s 49us/step - loss: 0.1041 - accuracy: 0.9661 - val_loss: 0.3209 - val_accuracy: 0.8849\n"
     ]
    }
   ],
   "source": [
    "# Creates model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=6, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 60us/step\n",
      "Model Performance on Test Data: Loss is  0.3442298119544983  and accuracy is  0.8732399940490723\n"
     ]
    }
   ],
   "source": [
    "# Evaluates testing performance\n",
    "evaluation = model.evaluate(test_data, test_labels)\n",
    "print(\"Model Performance on Test Data: Loss is \", evaluation[0], \" and accuracy is \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing hidden units from 16 to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "15000/15000 [==============================] - 1s 79us/step - loss: 0.4802 - accuracy: 0.7817 - val_loss: 0.3173 - val_accuracy: 0.8844\n",
      "Epoch 2/6\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.2556 - accuracy: 0.9057 - val_loss: 0.3117 - val_accuracy: 0.8758\n",
      "Epoch 3/6\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1949 - accuracy: 0.9270 - val_loss: 0.2873 - val_accuracy: 0.8869\n",
      "Epoch 4/6\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1431 - accuracy: 0.9506 - val_loss: 0.2927 - val_accuracy: 0.8895\n",
      "Epoch 5/6\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1125 - accuracy: 0.9613 - val_loss: 0.3211 - val_accuracy: 0.8847\n",
      "Epoch 6/6\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0767 - accuracy: 0.9747 - val_loss: 0.3994 - val_accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "# Creates model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=6, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 74us/step\n",
      "Model Performance on Test Data: Loss is  0.4535508701610565  and accuracy is  0.8525599837303162\n"
     ]
    }
   ],
   "source": [
    "# Evaluates testing performance\n",
    "evaluation = model.evaluate(test_data, test_labels)\n",
    "print(\"Model Performance on Test Data: Loss is \", evaluation[0], \" and accuracy is \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using diffrent loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 'mse' loss function instead of 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "15000/15000 [==============================] - 1s 53us/step - loss: 0.1706 - accuracy: 0.7834 - val_loss: 0.1199 - val_accuracy: 0.8753\n",
      "Epoch 2/6\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0931 - accuracy: 0.9053 - val_loss: 0.0928 - val_accuracy: 0.8912\n",
      "Epoch 3/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0671 - accuracy: 0.9297 - val_loss: 0.0848 - val_accuracy: 0.8937\n",
      "Epoch 4/6\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0518 - accuracy: 0.9463 - val_loss: 0.0819 - val_accuracy: 0.8938\n",
      "Epoch 5/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0428 - accuracy: 0.9568 - val_loss: 0.0830 - val_accuracy: 0.8889\n",
      "Epoch 6/6\n",
      "15000/15000 [==============================] - 1s 37us/step - loss: 0.0346 - accuracy: 0.9664 - val_loss: 0.0865 - val_accuracy: 0.8843\n"
     ]
    }
   ],
   "source": [
    "# Creates model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=6, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 52us/step\n",
      "Model Performance on Test Data: Loss is  0.09658927468061447  and accuracy is  0.8686000108718872\n"
     ]
    }
   ],
   "source": [
    "# Evaluates testing performance\n",
    "evaluation = model.evaluate(test_data, test_labels)\n",
    "print(\"Model Performance on Test Data: Loss is \", evaluation[0], \" and accuracy is \", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different activtion functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 'tanh' activation function instead of 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "15000/15000 [==============================] - 1s 54us/step - loss: 0.4782 - accuracy: 0.7935 - val_loss: 0.3582 - val_accuracy: 0.8651\n",
      "Epoch 2/6\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.2689 - accuracy: 0.9071 - val_loss: 0.2849 - val_accuracy: 0.8878\n",
      "Epoch 3/6\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.1898 - accuracy: 0.9351 - val_loss: 0.3257 - val_accuracy: 0.8658\n",
      "Epoch 4/6\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.1460 - accuracy: 0.9499 - val_loss: 0.2964 - val_accuracy: 0.8825\n",
      "Epoch 5/6\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.1121 - accuracy: 0.9623 - val_loss: 0.3450 - val_accuracy: 0.8755\n",
      "Epoch 6/6\n",
      "15000/15000 [==============================] - 1s 44us/step - loss: 0.0843 - accuracy: 0.9725 - val_loss: 0.3661 - val_accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "# Creates model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, batch_size=512, epochs=6, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 55us/step\n",
      "Model Performance on Test Data: Loss is  0.39115401850700376  and accuracy is  0.8659200072288513\n"
     ]
    }
   ],
   "source": [
    "# Evaluates testing performance\n",
    "evaluation = model.evaluate(test_data, test_labels)\n",
    "print(\"Model Performance on Test Data: Loss is \", evaluation[0], \" and accuracy is \", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
